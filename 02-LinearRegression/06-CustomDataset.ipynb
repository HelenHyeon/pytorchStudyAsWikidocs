{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- PyTorch에서 torch.utils.data.Dataset과 torch.utils.data.DataLoader를 제공받아 여러 학습을 간단히 수행할 수 있다.\r\n",
    "- torch.utils.data.Dataset : PyTorch에서 데이터셋을 제공하는 추상클래스이며 상속받아 직접 **커스텀 데이터셋(Custom Dataset)을 만들 수도 있다.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 커스텀 데이터셋 만들기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```py\r\n",
    "# 기본적인 뼈대\r\n",
    "class CustomDataset(torch.utils.data.Dataset)\r\n",
    "    def __init__(self):\r\n",
    "        # 데이터셋 전처리 부분\r\n",
    "    def __len__(self):\r\n",
    "        # 데이터셋의 길이. 즉, 총 샘플의 수를 적어부는 부분\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        # 데이터셋에서 특정 1개 샘플을 가져오는 함수\r\n",
    "```\r\n",
    "- len(dataset)을 했을 때 데이터셋의 크기를 리턴할 **len**\r\n",
    "- dataset[i]을 했을 때 i번째 샘플을 가져오도록 하는 인덱싱을 위한 **get_item**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Dataset으로 선형 회귀 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from torch.utils.data import Dataset\r\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Dataset 상속\r\n",
    "class CustomDataset(Dataset):\r\n",
    "    def __init__(self):\r\n",
    "        self.x_data = [[73, 80, 75],\r\n",
    "                        [93, 88, 93],\r\n",
    "                        [89, 91, 90],\r\n",
    "                        [96, 98, 100],\r\n",
    "                        [73, 66, 70]]\r\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\r\n",
    "    # 총 데이터 개수 리턴\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.x_data)\r\n",
    "    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\r\n",
    "    def __getitem__(self, index):\r\n",
    "        x = torch.FloatTensor(self.x_data[index])\r\n",
    "        y = torch.FloatTensor(self.y_data[index])\r\n",
    "        return x, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataset = CustomDataset()\r\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = torch.nn.Linear(3,1)\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "nb_epochs = 20\r\n",
    "for epoch in range(nb_epochs+1):\r\n",
    "    for batch_idx, samples in enumerate(dataloader):\r\n",
    "        x_train, y_train = samples\r\n",
    "        # H(x)\r\n",
    "        prediction = model(x_train)\r\n",
    "\r\n",
    "        # cost\r\n",
    "        cost = F.mse_loss(prediction, y_train)\r\n",
    "\r\n",
    "        # cost -> H(x)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\r\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\r\n",
    "        cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 6878.889648\n",
      "Epoch    0/20 Batch 2/3 Cost: 3239.421387\n",
      "Epoch    0/20 Batch 3/3 Cost: 482.584747\n",
      "Epoch    1/20 Batch 1/3 Cost: 213.048981\n",
      "Epoch    1/20 Batch 2/3 Cost: 119.504105\n",
      "Epoch    1/20 Batch 3/3 Cost: 12.366916\n",
      "Epoch    2/20 Batch 1/3 Cost: 2.105424\n",
      "Epoch    2/20 Batch 2/3 Cost: 20.526842\n",
      "Epoch    2/20 Batch 3/3 Cost: 0.703186\n",
      "Epoch    3/20 Batch 1/3 Cost: 6.238947\n",
      "Epoch    3/20 Batch 2/3 Cost: 2.991834\n",
      "Epoch    3/20 Batch 3/3 Cost: 2.489804\n",
      "Epoch    4/20 Batch 1/3 Cost: 0.338442\n",
      "Epoch    4/20 Batch 2/3 Cost: 6.678338\n",
      "Epoch    4/20 Batch 3/3 Cost: 5.662317\n",
      "Epoch    5/20 Batch 1/3 Cost: 4.786727\n",
      "Epoch    5/20 Batch 2/3 Cost: 3.055572\n",
      "Epoch    5/20 Batch 3/3 Cost: 2.959979\n",
      "Epoch    6/20 Batch 1/3 Cost: 3.028355\n",
      "Epoch    6/20 Batch 2/3 Cost: 5.274428\n",
      "Epoch    6/20 Batch 3/3 Cost: 1.992674\n",
      "Epoch    7/20 Batch 1/3 Cost: 8.118447\n",
      "Epoch    7/20 Batch 2/3 Cost: 4.227414\n",
      "Epoch    7/20 Batch 3/3 Cost: 1.174460\n",
      "Epoch    8/20 Batch 1/3 Cost: 6.304877\n",
      "Epoch    8/20 Batch 2/3 Cost: 0.859764\n",
      "Epoch    8/20 Batch 3/3 Cost: 7.471801\n",
      "Epoch    9/20 Batch 1/3 Cost: 3.400125\n",
      "Epoch    9/20 Batch 2/3 Cost: 7.548480\n",
      "Epoch    9/20 Batch 3/3 Cost: 4.959415\n",
      "Epoch   10/20 Batch 1/3 Cost: 6.424113\n",
      "Epoch   10/20 Batch 2/3 Cost: 5.427517\n",
      "Epoch   10/20 Batch 3/3 Cost: 1.095628\n",
      "Epoch   11/20 Batch 1/3 Cost: 5.744937\n",
      "Epoch   11/20 Batch 2/3 Cost: 1.616005\n",
      "Epoch   11/20 Batch 3/3 Cost: 7.285782\n",
      "Epoch   12/20 Batch 1/3 Cost: 2.756186\n",
      "Epoch   12/20 Batch 2/3 Cost: 4.961012\n",
      "Epoch   12/20 Batch 3/3 Cost: 2.859668\n",
      "Epoch   13/20 Batch 1/3 Cost: 1.237493\n",
      "Epoch   13/20 Batch 2/3 Cost: 3.949688\n",
      "Epoch   13/20 Batch 3/3 Cost: 9.075965\n",
      "Epoch   14/20 Batch 1/3 Cost: 2.804120\n",
      "Epoch   14/20 Batch 2/3 Cost: 8.204092\n",
      "Epoch   14/20 Batch 3/3 Cost: 2.647771\n",
      "Epoch   15/20 Batch 1/3 Cost: 0.760215\n",
      "Epoch   15/20 Batch 2/3 Cost: 10.498127\n",
      "Epoch   15/20 Batch 3/3 Cost: 3.110862\n",
      "Epoch   16/20 Batch 1/3 Cost: 0.526573\n",
      "Epoch   16/20 Batch 2/3 Cost: 4.278530\n",
      "Epoch   16/20 Batch 3/3 Cost: 9.510018\n",
      "Epoch   17/20 Batch 1/3 Cost: 3.102152\n",
      "Epoch   17/20 Batch 2/3 Cost: 4.664168\n",
      "Epoch   17/20 Batch 3/3 Cost: 3.050495\n",
      "Epoch   18/20 Batch 1/3 Cost: 3.324260\n",
      "Epoch   18/20 Batch 2/3 Cost: 4.700499\n",
      "Epoch   18/20 Batch 3/3 Cost: 2.361626\n",
      "Epoch   19/20 Batch 1/3 Cost: 8.512528\n",
      "Epoch   19/20 Batch 2/3 Cost: 4.176479\n",
      "Epoch   19/20 Batch 3/3 Cost: 0.797840\n",
      "Epoch   20/20 Batch 1/3 Cost: 3.996623\n",
      "Epoch   20/20 Batch 2/3 Cost: 4.992512\n",
      "Epoch   20/20 Batch 3/3 Cost: 1.869953\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "3019afab00293a1ae281e291b07de184983c2ba180a49ac4e0334f58b45935af"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}