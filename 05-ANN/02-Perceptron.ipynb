{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 퍼셉트론 (Perceptron)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Perceptron** : **다수의 입력으로부터 하나의 결과를 도출하는** 알고리즘으로 프랑크 로젠블라트가 1957년에 제안한 초기 형태의 인공 신경망이다.\r\n",
    "- 퍼셉트론은 실제 뇌를 구성하는 신경 세포인 뉴런의 동작과 유사하다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![뉴런](../img/perceptron1.png)\r\n",
    "- 뉴런은 가지돌기에서 신호를 받아들이고, 신호가 일정치 이상의 크기를 가질 경우 축삭돌기를 통해 신호를 전달한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![퍼셉트론](../img/perceptron2.png)\r\n",
    "- x : 입력값 (뉴런에서의 입력신호), 입력값 x는 각각의 가중치 W와 인공 뉴런에 전달된다.\r\n",
    "- W : 가중치(Weight), 신호를 전달하는 뉴런의 축삭돌기 역할을 한다. 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 의미이다.\r\n",
    "- y : 출력값 (뉴련에서의 출력신호)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **계단 함수(Step function)** : 각 입력값이 가중치와 곱해져 인공 뉴런에 보내지고, 그 값들의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런이 1을 출력, 넘지 않으면 0을 출력한다.\r\n",
    "![계단 함수의 예시](../img/perceptron3.png)\r\n",
    "- 계단 함수에 사용되는 임계치값을 수식에서는 보통 세타(θ)로 표현한다.\r\n",
    "![계단 함수 수식](../img/perceptron4.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위의 식에서 임계치를 좌변으로 넘기고 편향 b로 표현할 수도 있다.\r\n",
    "- 편향 b도 퍼셉트론의 입력으로 사용된다. (보통 그림에서는 입력값 1에 편향 b를 곱해지는 변수로 표현한다.)\r\n",
    "![편향 b를 포함한 퍼셉트론](../img/perceptron5.png)\r\n",
    "![편향 b로 표현한 계단함수 수식](../img/perceptron6.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **활성화 함수(Activation Function)** : 뉴런에서 출력값을 변경시키는 함수이다. 위의 계단 함수나 시그모이드 함수, 소프트맥스 함수 등도 활성화 함수 중 하나이다.\r\n",
    "- 퍼셉트론의 활성화 함수를 계단 함수에서 시그모이드 함수로 변경할 경우 로지스틱 회귀와 동일함을 볼 수 있다. 즉, 로지스틱 회귀 모델은 인공 신경망에서 하나의 인공 뉴런으로 볼 수 있다.\r\n",
    "- 인공 뉴런의 활성화 함수(위 퍼셉트론의 계단 함수) 수식\r\n",
    "    ![수식](../img/perceptron7.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 단층 퍼셉트론"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![단층 퍼셉트론](../img/perceptron8.png)\r\n",
    "- 단층 퍼셉트론 : 입력층(input layer)과 출력층(output layer) 두 단계로만 이루어딘 퍼셉트론이다.\r\n",
    "- 단층 퍼셉트론을 이용하여 AND, NAND, OR 게이트를 쉽게 구현할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AND 게이트\r\n",
    "![AND 게이트](../img/perceptron9.png)\r\n",
    "- 두 개의 입력 값이 모두 1인 경우에만 출력값이 1이 나오는 구조이다.\r\n",
    "```py\r\n",
    "def AND_gate(x1, x2):\r\n",
    "    w1=0.5\r\n",
    "    w2=0.5\r\n",
    "    b=-0.7\r\n",
    "    result = x1*w1 + x2*w2 + b\r\n",
    "    if result <= 0:\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        return 1\r\n",
    "```\r\n",
    "![AND게이트 시각화](../img/perceptron12.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NAND 게이트\r\n",
    "![NAND 게이트](../img/perceptron10.png)\r\n",
    "- 두 개의 입력 값이 모두 1인 경우에만 출력값이 0이 나오는 구조이다.\r\n",
    "```py\r\n",
    "def NAND_gate(x1, x2):\r\n",
    "    w1=-0.5\r\n",
    "    w2=-0.5\r\n",
    "    b=0.7\r\n",
    "    result = x1*w1 + x2*w2 + b\r\n",
    "    if result <= 0:\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        return 1\r\n",
    "```\r\n",
    "![NAND게이트 시각화](../img/perceptron13.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OR 게이트\r\n",
    "![OR 게이트](../img/perceptron11.png)\r\n",
    "- 두 개의 입력 값이 모두 0인 경우에만 출력값이 0이 나오는 구조이다.\r\n",
    "```py\r\n",
    "def OR_gate(x1, x2):\r\n",
    "    w1=0.6\r\n",
    "    w2=0.6\r\n",
    "    b=-0.5\r\n",
    "    result = x1*w1 + x2*w2 + b\r\n",
    "    if result <= 0:\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        return 1\r\n",
    "```\r\n",
    "![OR게이트 시각화](../img/perceptron14.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![XOR GATE](../img/perceptron15.png)\r\n",
    "- AND, NAND, OR과 같은 게이트는 직선 하나로 구현이 가능하지만 XOR 게이트와 같은 경우 직선 하나로 결과를 나누는 것이 불가능하다.\r\n",
    "- 직선이 아닌 곡선, 비선형 영역으로 분리하여 구현하기 위해 다층 퍼셉트론을 사용한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 다층 퍼셉트론(MultiLayer Perceptron, MLP)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- XOR 게이트의 경우 기존의 AND, NAND, OR 게이트를 조합하여 만들 수 있다. 즉, 퍼셉트론의 층(layer)을 더 쌓아서 만들 수 있다.\r\n",
    "- **다층 퍼셉트론** : 입력층과 출력층, 그 사이의 1개 이상의 **은닉층(hidden layer)** 으로 이루어진 퍼셉트론이다. MLP라고도 부른다.\r\n",
    "![XOR GATE](../img/perceptron16.jpg)\r\n",
    "```py\r\n",
    "def XOR_gate(x1, x2):\r\n",
    "    result = AND_gate(NAND_gate(x1, x2), OR_gate(x1, x2))\r\n",
    "    return result\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![은닉층이 2개인 경우의 퍼셉트론](../img/perceptron17.png)\r\n",
    "- **심층 신경망(Deep Neural Network, DNN)** : 은닉층(hidden layer)이 2개 이상인 신경망을 뜻한다.\r\n",
    "- **학습(training)** : 기계가 가중치를 스스로 찾아내도록 자동화 시키는 것으로 **손실 함수(Loss function)** 와 **옵티마이저(Optimizer)** 를 사용한다.\r\n",
    "- **딥 러닝(Deep Learning)** : 심층 신경망을 학습시키는 것"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "3019afab00293a1ae281e291b07de184983c2ba180a49ac4e0334f58b45935af"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}