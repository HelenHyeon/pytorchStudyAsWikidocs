{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 인공 신경망 (Neural Network)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 예제 설명\r\n",
    "    - 입력층, 은닉층, 출력층 총 3개의 층을 가진다.\r\n",
    "    - 각각 두개의 입력, 출력과 은닉층 뉴런을 사용한다.\r\n",
    "    - 은닉층과 출력층의 모든 뉴런은 시그모이드 함수를 활성화 함수로 사용한다.\r\n",
    "    - 인공 신경망에 존재하는 모든 가중치 W에 대해서 역전파를 통해 업데이트하는 것을 목표로 한다.\r\n",
    "    - 편향 b는 고려하지 않는다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![인공 신경망 예시](../img/BP.png)\r\n",
    "- z : 아직 시그모이드 함수를 거치치 않은 이전층의 가중합을 의미하며, 은닉층과 출력층의 모든 뉴런에 존재한다. 즉, 활정화 함수의 입력이다.\r\n",
    "- h(또는 o) : z가 시그모이드 함수를 지난 후의 값으로 각 뉴런의 출력값을 의미한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 순전파 (Forward Propagation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![순전파img](../img/BP1.png)\r\n",
    "- 파란색 숫자 : 입력값, 빨간색 숫자 : 각 가중치 값\r\n",
    "1. 각 입력은 입력층->은닉층 방향으로 향한다. 입력은 각각 해당하는 가중치와 곱해지고 가중합으로 계산되어 은닉층 뉴런의 시그모이드 함수 입력값(z₁, z₂)이 된다.\r\n",
    "    - z₁ = 0.8\r\n",
    "2. z₁, z₂는 시그모이드 함수의 입력값이 되며 그 결과값이 h₁, h₂에 해당한다.\r\n",
    "    - h₁ = sigmoid(z₁) = 0.51998934\r\n",
    "3. h₁, h₂는 각각 해당하는 가중치와 곱해져 출력층의 뉴런으로 향하고 가중합 되어 뉴런의 시그모이드 함수 입력값이 된다.\r\n",
    "4. z₃, z₄이 출력층 뉴런에서 시그모이드 함수를 지나 최종 출력값(예측값)이 된다.\r\n",
    "    - o₁ = sigcoid(z₃)\r\n",
    "5. 예측값과 실제값의 오차를 계산하기 위한 오차 함수를 선택해야 한다. 오차를 계산하기 위한 솔실 함수로 평균 제곱 오차(MSE)를 사용한다.\r\n",
    "    - target : 실제값, output : 예측값, Etotal : 전체 오차\r\n",
    "    ![오차 계산](../img/BP2.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BackPropagation (역전파)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 역전파 : 순전파와 반대로 출력층에서 입력층 방향으로 계산하며 가중치를 업데이트 하는 것\r\n",
    "- 역전파 1단계 : 출력층과 N층(출력층 바로 이전 은닉층) 사이의 가중치를 업데이트하는 단계\r\n",
    "- 역전파 2단계 : N층과 N층의 이전층 사이의 가중치를 업데이트 하는 단계"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 역전파 1단계"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![역전파img](../img/BP3.png)\r\n",
    "1. W5에 대한 업데이트를 위해 밑의 수식을 실행해야 한다.\r\n",
    "    ![미분의 연쇄 법칙](../img/BP4.png)\r\n",
    "    1. 위 수식에서 Etotal은 앞서 순전파 진행 후 계산한 전체 오차값이다.\r\n",
    "        ![Etotal](../img/BP5.png)\r\n",
    "    2. o₁은 시그모이드 함수의 출력값이다. (시그모이드 함수 미분 : f(x)*(1-f(x)))\r\n",
    "        ![미분의연쇄법칙 두번째 항 미분 결과](../img/BP6.png)\r\n",
    "    3. 세번째 항은 h₁의 값과 동일하다.\r\n",
    "        ![세 번째 항](../img/BP7.png)\r\n",
    "    4. 우변의 모든 항을 곱해준다.\r\n",
    "        ![우변 계산](../img/BP8.png)\r\n",
    "2. 하이퍼파라미터에 해당하는 학습률 a를 0.5라고 가정하여 가중치를 업데이트한다.\r\n",
    "    ![가중치 업데이트](../img/BP9.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 역전파 2단계"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![역전파 2단계](../img/BP10.png)\r\n",
    "1. W1에 대한 업데이트를 위해 밑의 수식을 실행한다.\r\n",
    "    ![미분의 연쇄 법칙](../img/BP11.png)\r\n",
    "    1. 위의 식에서 우변의 첫번째 항\r\n",
    "        ![첫번째 항](../img/BP12.png)\r\n",
    "        1. 위의 식의 우변 첫번째 항\r\n",
    "            ![첫번째 항](../img/BP13.png)\r\n",
    "        2. 우변 두번째 항\r\n",
    "            ![두번째 항](../img/BP14.png)\r\n",
    "    2. 우변의 두번째 항\r\n",
    "        ![두번째 항](../img/BP15.png)\r\n",
    "    3. 우변의 세번째 항\r\n",
    "        ![세번째 항](../img/BP16.png)\r\n",
    "    4. 즉 결과는 다음과 같다.\r\n",
    "        ![계산](../img/BP17.png)\r\n",
    "2. 경사 하강법을 통해 가중치를 업데이트한다.\r\n",
    "    ![가중치 업데이트](../img/BP18.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 결과"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 업데이트 된 가중치에 대해 다시 순전파를 진행해 오차 감소를 확인한다.\r\n",
    "![결과](../img/BP19.png)\r\n",
    "- 기존 오차 : 0.02397190, 현재 오차 : 0.02323634 로 역전파 한번으로 오차가 감소하였다.\r\n",
    "- 인공 신경망의 학습 : 오차를 최소화하는 가중치를 찾는 목적으로 순전파와 역전파를 반복하는 것"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}